"""
ê¸°ìˆ ì§€í‘œ (Technical Analysis) í”¼ì²˜ ìƒì„± ëª¨ë“ˆ

ë‹¤ì–‘í•œ ê¸°ìˆ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ í”¼ì²˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

from pathlib import Path
from typing import List, Optional, Dict, Any

import pandas as pd
import numpy as np
import polars as pl
from loguru import logger

try:
    import ta
    TA_AVAILABLE = True
except ImportError:
    logger.warning("ta ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€í‘œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    TA_AVAILABLE = False

from ..utils.paths import get_raw_data_path, get_silver_data_path, ensure_dir


def calculate_sma(data: pd.DataFrame, window: int = 20) -> pd.Series:
    """ë‹¨ìˆœ ì´ë™í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: ê°€ê²© ë°ì´í„°
        window: ì´ë™í‰ê·  ê¸°ê°„
        
    Returns:
        SMA ì‹œë¦¬ì¦ˆ
    """
    return data['close'].rolling(window=window).mean()


def calculate_ema(data: pd.DataFrame, window: int = 20) -> pd.Series:
    """ì§€ìˆ˜ ì´ë™í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: ê°€ê²© ë°ì´í„°
        window: ì´ë™í‰ê·  ê¸°ê°„
        
    Returns:
        EMA ì‹œë¦¬ì¦ˆ
    """
    return data['close'].ewm(span=window).mean()


def calculate_rsi(data: pd.DataFrame, window: int = 14) -> pd.Series:
    """RSI (Relative Strength Index)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: ê°€ê²© ë°ì´í„°
        window: RSI ê¸°ê°„
        
    Returns:
        RSI ì‹œë¦¬ì¦ˆ
    """
    if TA_AVAILABLE:
        return ta.momentum.RSIIndicator(data['close'], window=window).rsi()
    
    # ìˆ˜ë™ RSI ê³„ì‚°
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi


def calculate_macd(data: pd.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> Dict[str, pd.Series]:
    """MACDë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: ê°€ê²© ë°ì´í„°
        fast: ë¹ ë¥¸ EMA ê¸°ê°„
        slow: ëŠë¦° EMA ê¸°ê°„
        signal: ì‹œê·¸ë„ ë¼ì¸ ê¸°ê°„
        
    Returns:
        MACD, Signal, Histogram ë”•ì…”ë„ˆë¦¬
    """
    if TA_AVAILABLE:
        macd_indicator = ta.trend.MACD(data['close'], window_fast=fast, window_slow=slow, window_sign=signal)
        return {
            'macd': macd_indicator.macd(),
            'macd_signal': macd_indicator.macd_signal(),
            'macd_histogram': macd_indicator.macd_diff()
        }
    
    # ìˆ˜ë™ MACD ê³„ì‚°
    ema_fast = data['close'].ewm(span=fast).mean()
    ema_slow = data['close'].ewm(span=slow).mean()
    macd = ema_fast - ema_slow
    macd_signal = macd.ewm(span=signal).mean()
    macd_histogram = macd - macd_signal
    
    return {
        'macd': macd,
        'macd_signal': macd_signal,
        'macd_histogram': macd_histogram
    }


def calculate_bollinger_bands(data: pd.DataFrame, window: int = 20, std_dev: float = 2) -> Dict[str, pd.Series]:
    """ë³¼ë¦°ì € ë°´ë“œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: ê°€ê²© ë°ì´í„°
        window: ì´ë™í‰ê·  ê¸°ê°„
        std_dev: í‘œì¤€í¸ì°¨ ë°°ìˆ˜
        
    Returns:
        Upper, Middle, Lower ë°´ë“œ ë”•ì…”ë„ˆë¦¬
    """
    if TA_AVAILABLE:
        bb = ta.volatility.BollingerBands(data['close'], window=window, window_dev=std_dev)
        return {
            'bb_upper': bb.bollinger_hband(),
            'bb_middle': bb.bollinger_mavg(),
            'bb_lower': bb.bollinger_lband()
        }
    
    # ìˆ˜ë™ ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
    sma = data['close'].rolling(window=window).mean()
    std = data['close'].rolling(window=window).std()
    
    return {
        'bb_upper': sma + (std * std_dev),
        'bb_middle': sma,
        'bb_lower': sma - (std * std_dev)
    }


def calculate_atr(data: pd.DataFrame, window: int = 14) -> pd.Series:
    """ATR (Average True Range)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: OHLC ë°ì´í„°
        window: ATR ê¸°ê°„
        
    Returns:
        ATR ì‹œë¦¬ì¦ˆ
    """
    if TA_AVAILABLE:
        return ta.volatility.AverageTrueRange(
            data['high'], data['low'], data['close'], window=window
        ).average_true_range()
    
    # ìˆ˜ë™ ATR ê³„ì‚°
    high_low = data['high'] - data['low']
    high_close_prev = np.abs(data['high'] - data['close'].shift(1))
    low_close_prev = np.abs(data['low'] - data['close'].shift(1))
    
    true_range = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)
    atr = true_range.rolling(window=window).mean()
    
    return atr


def calculate_stochastic(data: pd.DataFrame, k_window: int = 14, d_window: int = 3) -> Dict[str, pd.Series]:
    """ìŠ¤í† ìºìŠ¤í‹± ì˜¤ì‹¤ë ˆì´í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: OHLC ë°ì´í„°
        k_window: %K ê¸°ê°„
        d_window: %D ê¸°ê°„
        
    Returns:
        %K, %D ë”•ì…”ë„ˆë¦¬
    """
    if TA_AVAILABLE:
        stoch = ta.momentum.StochasticOscillator(
            data['high'], data['low'], data['close'], window=k_window, smooth_window=d_window
        )
        return {
            'stoch_k': stoch.stoch(),
            'stoch_d': stoch.stoch_signal()
        }
    
    # ìˆ˜ë™ ìŠ¤í† ìºìŠ¤í‹± ê³„ì‚°
    lowest_low = data['low'].rolling(window=k_window).min()
    highest_high = data['high'].rolling(window=k_window).max()
    
    k_percent = 100 * (data['close'] - lowest_low) / (highest_high - lowest_low)
    d_percent = k_percent.rolling(window=d_window).mean()
    
    return {
        'stoch_k': k_percent,
        'stoch_d': d_percent
    }


def calculate_volume_indicators(data: pd.DataFrame) -> Dict[str, pd.Series]:
    """ê±°ë˜ëŸ‰ ì§€í‘œë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: OHLCV ë°ì´í„°
        
    Returns:
        ê±°ë˜ëŸ‰ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    indicators = {}
    
    # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
    indicators['volume_sma_20'] = data['volume'].rolling(window=20).mean()
    indicators['volume_sma_50'] = data['volume'].rolling(window=50).mean()
    
    # ê±°ë˜ëŸ‰ ë¹„ìœ¨
    indicators['volume_ratio'] = data['volume'] / indicators['volume_sma_20']
    
    # ê°€ê²© ë³€í™”ìœ¨ê³¼ ê±°ë˜ëŸ‰ì˜ ê´€ê³„
    price_change = data['close'].pct_change()
    indicators['price_volume_trend'] = (price_change * data['volume']).cumsum()
    
    if TA_AVAILABLE:
        # On-Balance Volume
        indicators['obv'] = ta.volume.OnBalanceVolumeIndicator(
            data['close'], data['volume']
        ).on_balance_volume()
        
        # Volume Weighted Average Price (ê·¼ì‚¬ì¹˜)
        indicators['vwap'] = (data['close'] * data['volume']).rolling(window=20).sum() / \
                           data['volume'].rolling(window=20).sum()
    
    return indicators


def calculate_price_features(data: pd.DataFrame) -> Dict[str, pd.Series]:
    """ê°€ê²© ê¸°ë°˜ í”¼ì²˜ë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        data: OHLC ë°ì´í„°
        
    Returns:
        ê°€ê²© í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
    """
    features = {}
    
    # ìˆ˜ìµë¥ 
    features['returns'] = data['close'].pct_change()
    features['log_returns'] = np.log(data['close'] / data['close'].shift(1))
    
    # ë³€ë™ì„± (Rolling)
    features['volatility_10'] = features['returns'].rolling(window=10).std()
    features['volatility_20'] = features['returns'].rolling(window=20).std()
    
    # ê°€ê²© ì°¨ì´
    features['high_low_pct'] = (data['high'] - data['low']) / data['close']
    features['open_close_pct'] = (data['close'] - data['open']) / data['open']
    
    # ê°­
    features['gap'] = (data['open'] - data['close'].shift(1)) / data['close'].shift(1)
    
    # ìƒëŒ€ì  ìœ„ì¹˜
    features['close_position'] = (data['close'] - data['low']) / (data['high'] - data['low'])
    
    return features


def add_all_indicators(data: pd.DataFrame) -> pd.DataFrame:
    """ëª¨ë“  ê¸°ìˆ ì§€í‘œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        data: ê¸°ë³¸ OHLCV ë°ì´í„°
        
    Returns:
        ê¸°ìˆ ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    logger.info(f"ğŸ“Š ê¸°ìˆ ì§€í‘œ ê³„ì‚° ì‹œì‘: {len(data)} í–‰")
    
    # ë³µì‚¬ë³¸ ìƒì„±
    result = data.copy()
    
    # ì´ë™í‰ê· 
    result['sma_5'] = calculate_sma(data, 5)
    result['sma_10'] = calculate_sma(data, 10)
    result['sma_20'] = calculate_sma(data, 20)
    result['sma_50'] = calculate_sma(data, 50)
    
    result['ema_5'] = calculate_ema(data, 5)
    result['ema_10'] = calculate_ema(data, 10)
    result['ema_20'] = calculate_ema(data, 20)
    
    # ëª¨ë©˜í…€ ì§€í‘œ
    result['rsi'] = calculate_rsi(data)
    
    # MACD
    macd_dict = calculate_macd(data)
    for key, value in macd_dict.items():
        result[key] = value
    
    # ë³¼ë¦°ì € ë°´ë“œ
    bb_dict = calculate_bollinger_bands(data)
    for key, value in bb_dict.items():
        result[key] = value
    
    # ë³€ë™ì„± ì§€í‘œ
    result['atr'] = calculate_atr(data)
    
    # ìŠ¤í† ìºìŠ¤í‹±
    stoch_dict = calculate_stochastic(data)
    for key, value in stoch_dict.items():
        result[key] = value
    
    # ê±°ë˜ëŸ‰ ì§€í‘œ
    volume_dict = calculate_volume_indicators(data)
    for key, value in volume_dict.items():
        result[key] = value
    
    # ê°€ê²© í”¼ì²˜
    price_dict = calculate_price_features(data)
    for key, value in price_dict.items():
        result[key] = value
    
    logger.success(f"âœ… ê¸°ìˆ ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {len(result.columns)} ì»¬ëŸ¼")
    return result


def process_single_ticker(ticker_data: pd.DataFrame) -> pd.DataFrame:
    """ë‹¨ì¼ ì¢…ëª© ë°ì´í„°ì— ëŒ€í•´ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        ticker_data: ì¢…ëª© ë°ì´í„°
        
    Returns:
        í”¼ì²˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    # ë‚ ì§œ ì •ë ¬
    ticker_data = ticker_data.sort_values('date').reset_index(drop=True)
    
    # ê¸°ìˆ ì§€í‘œ ì¶”ê°€
    enhanced_data = add_all_indicators(ticker_data)
    
    # ê²°ì¸¡ì¹˜ê°€ ë„ˆë¬´ ë§ì€ ì´ˆê¸° í–‰ë“¤ ì œê±°
    enhanced_data = enhanced_data.dropna(thresh=len(enhanced_data.columns) * 0.7)
    
    return enhanced_data


def create_features(
    input_dir: Path,
    output_dir: Path,
    force: bool = False
) -> str:
    """ì›ë³¸ ë°ì´í„°ì—ì„œ í”¼ì²˜ë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        input_dir: ì›ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        force: ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° ì—¬ë¶€
        
    Returns:
        ê²°ê³¼ ë©”ì‹œì§€
    """
    logger.info(f"ğŸ”§ í”¼ì²˜ ìƒì„± ì‹œì‘: {input_dir} -> {output_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    ensure_dir(output_dir)
    
    # ì›ë³¸ CSV íŒŒì¼ë“¤ ì°¾ê¸°
    csv_files = list(input_dir.rglob("*.csv"))
    
    if not csv_files:
        return "ì›ë³¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    logger.info(f"ğŸ“ ë°œê²¬ëœ íŒŒì¼: {len(csv_files)} ê°œ")
    
    all_features = []
    processed_count = 0
    
    for csv_file in csv_files:
        try:
            # íŒŒì¼ ì½ê¸°
            data = pd.read_csv(csv_file)
            data['date'] = pd.to_datetime(data['date'])
            
            # í”¼ì²˜ ìƒì„±
            features = process_single_ticker(data)
            
            if not features.empty:
                all_features.append(features)
                processed_count += 1
                logger.debug(f"âœ… {csv_file.name} ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {csv_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue
    
    if not all_features:
        return "ì²˜ë¦¬ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ëª¨ë“  ë°ì´í„° í•©ì¹˜ê¸°
    combined_features = pd.concat(all_features, ignore_index=True)
    
    # MultiIndex ìƒì„± (ë‚ ì§œ, ì¢…ëª©)
    combined_features = combined_features.set_index(['date', 'ticker']).sort_index()
    
    # Parquetìœ¼ë¡œ ì €ì¥
    output_file = output_dir / "features.parquet"
    
    if output_file.exists() and not force:
        return f"íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {output_file} (--force ì˜µì…˜ ì‚¬ìš©)"
    
    combined_features.to_parquet(output_file)
    
    logger.success(f"âœ… í”¼ì²˜ ìƒì„± ì™„ë£Œ: {processed_count} ì¢…ëª©, {len(combined_features)} í–‰")
    return f"í”¼ì²˜ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}"


def load_features(file_path: Optional[Path] = None) -> pd.DataFrame:
    """ì €ì¥ëœ í”¼ì²˜ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        file_path: í”¼ì²˜ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ)
        
    Returns:
        í”¼ì²˜ ë°ì´í„°í”„ë ˆì„
    """
    if file_path is None:
        file_path = get_silver_data_path("features.parquet")
    
    if not file_path.exists():
        raise FileNotFoundError(f"í”¼ì²˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    
    return pd.read_parquet(file_path)


# CLI ì§ì ‘ ì‹¤í–‰ìš©
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 3:
        print("ì‚¬ìš©ë²•: python -m src.features.ta_factors INPUT_DIR OUTPUT_DIR")
        sys.exit(1)
    
    input_path = Path(sys.argv[1])
    output_path = Path(sys.argv[2])
    
    result = create_features(input_path, output_path)
    print(result)