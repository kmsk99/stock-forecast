"""
ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ ì§€í‘œ ê³„ì‚° ëª¨ë“ˆ

CAGR, Sharpe, MDD, CVaR ë“± ë‹¤ì–‘í•œ ì„±ê³¼ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
"""

from typing import Dict, Any, Optional, List, Tuple
import warnings

import pandas as pd
import numpy as np
from loguru import logger


def calculate_returns_metrics(returns: pd.Series) -> Dict[str, float]:
    """ìˆ˜ìµë¥  ê¸°ë°˜ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        
    Returns:
        ìˆ˜ìµë¥  ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    returns = returns.dropna()
    
    if len(returns) == 0:
        return {}
    
    # ê¸°ë³¸ í†µê³„
    total_return = (1 + returns).prod() - 1
    n_periods = len(returns)
    
    # ì—°ìœ¨í™” (252 ê±°ë˜ì¼ ê¸°ì¤€)
    trading_days = 252
    years = n_periods / trading_days
    
    # CAGR (Compound Annual Growth Rate)
    if years > 0 and total_return > -1:
        cagr = (1 + total_return) ** (1 / years) - 1
    else:
        cagr = 0.0
    
    # Annualized Return (ì‚°ìˆ í‰ê·  ë°©ì‹)
    annualized_return = returns.mean() * trading_days
    
    # ë³€ë™ì„± (Volatility)
    volatility = returns.std() * np.sqrt(trading_days)
    
    return {
        'total_return': total_return,
        'cagr': cagr,
        'annualized_return': annualized_return,
        'volatility': volatility,
        'trading_days': n_periods,
        'years': years
    }


def calculate_risk_adjusted_metrics(returns: pd.Series, risk_free_rate: float = 0.02) -> Dict[str, float]:
    """ìœ„í—˜ì¡°ì • ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        risk_free_rate: ë¬´ìœ„í—˜ ìˆ˜ìµë¥  (ì—°ìœ¨)
        
    Returns:
        ìœ„í—˜ì¡°ì • ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    returns = returns.dropna()
    
    if len(returns) == 0:
        return {}
    
    # ê¸°ë³¸ ì§€í‘œ
    annualized_return = returns.mean() * 252
    volatility = returns.std() * np.sqrt(252)
    
    # Sharpe Ratio
    if volatility > 0:
        sharpe_ratio = (annualized_return - risk_free_rate) / volatility
    else:
        sharpe_ratio = 0.0
    
    # Sortino Ratio (í•˜ë°© ë³€ë™ì„±ë§Œ ê³ ë ¤)
    downside_returns = returns[returns < 0]
    if len(downside_returns) > 0:
        downside_deviation = downside_returns.std() * np.sqrt(252)
        if downside_deviation > 0:
            sortino_ratio = (annualized_return - risk_free_rate) / downside_deviation
        else:
            sortino_ratio = np.inf
    else:
        sortino_ratio = np.inf
    
    # Information Ratio (ëŒ€ ë²¤ì¹˜ë§ˆí¬, ì—¬ê¸°ì„œëŠ” ë¬´ìœ„í—˜ìˆ˜ìµë¥  ëŒ€ë¹„)
    excess_returns = returns - (risk_free_rate / 252)
    tracking_error = excess_returns.std() * np.sqrt(252)
    
    if tracking_error > 0:
        information_ratio = excess_returns.mean() * 252 / tracking_error
    else:
        information_ratio = 0.0
    
    return {
        'sharpe_ratio': sharpe_ratio,
        'sortino_ratio': sortino_ratio,
        'information_ratio': information_ratio,
        'tracking_error': tracking_error,
        'downside_deviation': downside_deviation if len(downside_returns) > 0 else 0.0
    }


def calculate_drawdown_metrics(returns: pd.Series) -> Dict[str, Any]:
    """ë“œë¡œìš°ë‹¤ìš´ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        
    Returns:
        ë“œë¡œìš°ë‹¤ìš´ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    returns = returns.dropna()
    
    if len(returns) == 0:
        return {}
    
    # ëˆ„ì  ìˆ˜ìµë¥ 
    cumulative_returns = (1 + returns).cumprod()
    
    # ìµœê³ ì  (Running Maximum)
    rolling_max = cumulative_returns.expanding().max()
    
    # ë“œë¡œìš°ë‹¤ìš´
    drawdown = (cumulative_returns - rolling_max) / rolling_max
    
    # Maximum Drawdown
    max_drawdown = drawdown.min()
    
    # Maximum Drawdown ê¸°ê°„
    max_dd_start = None
    max_dd_end = None
    max_dd_duration = 0
    
    if max_drawdown < 0:
        max_dd_idx = drawdown.idxmin()
        
        # ì‹œì‘ì  ì°¾ê¸° (ìµœê³ ì )
        start_candidates = rolling_max[:max_dd_idx]
        if len(start_candidates) > 0:
            max_dd_start = start_candidates[start_candidates == start_candidates.max()].index[-1]
        
        # ì¢…ë£Œì  ì°¾ê¸° (íšŒë³µì )
        recovery_value = rolling_max.loc[max_dd_idx]
        recovery_candidates = cumulative_returns[max_dd_idx:]
        recovery_points = recovery_candidates[recovery_candidates >= recovery_value]
        
        if len(recovery_points) > 0:
            max_dd_end = recovery_points.index[0]
        else:
            max_dd_end = cumulative_returns.index[-1]  # ì•„ì§ íšŒë³µ ì•ˆë¨
        
        # ê¸°ê°„ ê³„ì‚°
        if max_dd_start and max_dd_end:
            max_dd_duration = (max_dd_end - max_dd_start).days
    
    # Average Drawdown
    drawdown_periods = []
    current_dd_start = None
    
    for i, (date, dd) in enumerate(drawdown.items()):
        if dd < 0 and current_dd_start is None:
            current_dd_start = i
        elif dd >= 0 and current_dd_start is not None:
            dd_period = drawdown.iloc[current_dd_start:i]
            if len(dd_period) > 0:
                drawdown_periods.append({
                    'max_dd': dd_period.min(),
                    'duration': len(dd_period),
                    'start_date': dd_period.index[0],
                    'end_date': dd_period.index[-1]
                })
            current_dd_start = None
    
    # ë§ˆì§€ë§‰ ë“œë¡œìš°ë‹¤ìš´ì´ ëë‚˜ì§€ ì•Šì€ ê²½ìš°
    if current_dd_start is not None:
        dd_period = drawdown.iloc[current_dd_start:]
        if len(dd_period) > 0:
            drawdown_periods.append({
                'max_dd': dd_period.min(),
                'duration': len(dd_period),
                'start_date': dd_period.index[0],
                'end_date': dd_period.index[-1]
            })
    
    # í‰ê·  ë“œë¡œìš°ë‹¤ìš´
    if drawdown_periods:
        avg_drawdown = np.mean([dd['max_dd'] for dd in drawdown_periods])
        avg_dd_duration = np.mean([dd['duration'] for dd in drawdown_periods])
    else:
        avg_drawdown = 0.0
        avg_dd_duration = 0.0
    
    # Calmar Ratio (CAGR / |Max Drawdown|)
    cagr = calculate_returns_metrics(returns).get('cagr', 0)
    calmar_ratio = cagr / abs(max_drawdown) if max_drawdown < 0 else np.inf
    
    return {
        'max_drawdown': max_drawdown,
        'max_dd_start_date': max_dd_start,
        'max_dd_end_date': max_dd_end,
        'max_dd_duration_days': max_dd_duration,
        'avg_drawdown': avg_drawdown,
        'avg_dd_duration_days': avg_dd_duration,
        'calmar_ratio': calmar_ratio,
        'drawdown_series': drawdown,
        'drawdown_periods': drawdown_periods,
        'n_drawdown_periods': len(drawdown_periods)
    }


def calculate_tail_risk_metrics(returns: pd.Series, confidence_levels: List[float] = [0.95, 0.99]) -> Dict[str, float]:
    """ê¼¬ë¦¬ ìœ„í—˜ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        confidence_levels: ì‹ ë¢°ìˆ˜ì¤€ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê¼¬ë¦¬ ìœ„í—˜ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    returns = returns.dropna()
    
    if len(returns) == 0:
        return {}
    
    metrics = {}
    
    for confidence in confidence_levels:
        alpha = 1 - confidence
        
        # Value at Risk (VaR)
        var = returns.quantile(alpha)
        metrics[f'var_{int(confidence*100)}'] = var
        
        # Conditional Value at Risk (CVaR) / Expected Shortfall
        cvar = returns[returns <= var].mean()
        metrics[f'cvar_{int(confidence*100)}'] = cvar
        
        # ì—°ìœ¨í™”
        metrics[f'var_{int(confidence*100)}_annual'] = var * np.sqrt(252)
        metrics[f'cvar_{int(confidence*100)}_annual'] = cvar * np.sqrt(252)
    
    # Skewness and Kurtosis
    metrics['skewness'] = returns.skew()
    metrics['kurtosis'] = returns.kurtosis()
    metrics['excess_kurtosis'] = returns.kurtosis() - 3
    
    # Tail Ratio (95% quantile / 5% quantile)
    q95 = returns.quantile(0.95)
    q5 = returns.quantile(0.05)
    if q5 != 0:
        metrics['tail_ratio'] = q95 / abs(q5)
    else:
        metrics['tail_ratio'] = np.inf
    
    return metrics


def calculate_consistency_metrics(returns: pd.Series) -> Dict[str, float]:
    """ì¼ê´€ì„± ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        
    Returns:
        ì¼ê´€ì„± ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    returns = returns.dropna()
    
    if len(returns) == 0:
        return {}
    
    # Win Rate (ì–‘ì˜ ìˆ˜ìµë¥  ë¹„ìœ¨)
    win_rate = (returns > 0).mean()
    
    # Best/Worst Day
    best_day = returns.max()
    worst_day = returns.min()
    
    # Profit Factor (ì´ ì´ìµ / ì´ ì†ì‹¤)
    positive_returns = returns[returns > 0]
    negative_returns = returns[returns < 0]
    
    if len(negative_returns) > 0 and negative_returns.sum() != 0:
        profit_factor = positive_returns.sum() / abs(negative_returns.sum())
    else:
        profit_factor = np.inf
    
    # Average Win/Loss
    avg_win = positive_returns.mean() if len(positive_returns) > 0 else 0.0
    avg_loss = negative_returns.mean() if len(negative_returns) > 0 else 0.0
    
    # Win/Loss Ratio
    if avg_loss != 0:
        win_loss_ratio = abs(avg_win / avg_loss)
    else:
        win_loss_ratio = np.inf
    
    # Monthly returns analysis
    monthly_returns = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
    monthly_win_rate = (monthly_returns > 0).mean() if len(monthly_returns) > 0 else 0.0
    
    return {
        'win_rate': win_rate,
        'monthly_win_rate': monthly_win_rate,
        'best_day': best_day,
        'worst_day': worst_day,
        'profit_factor': profit_factor,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'win_loss_ratio': win_loss_ratio,
        'n_positive_days': len(positive_returns),
        'n_negative_days': len(negative_returns),
        'n_neutral_days': len(returns) - len(positive_returns) - len(negative_returns)
    }


def calculate_performance_metrics(
    returns: pd.Series,
    risk_free_rate: float = 0.02,
    benchmark_returns: Optional[pd.Series] = None
) -> Dict[str, Any]:
    """ì¢…í•© ì„±ê³¼ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        risk_free_rate: ë¬´ìœ„í—˜ ìˆ˜ìµë¥  (ì—°ìœ¨)
        benchmark_returns: ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
        
    Returns:
        ì¢…í•© ì„±ê³¼ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    logger.debug(f"ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì‹œì‘: {len(returns)} ì¼")
    
    all_metrics = {}
    
    # ìˆ˜ìµë¥  ì§€í‘œ
    all_metrics.update(calculate_returns_metrics(returns))
    
    # ìœ„í—˜ì¡°ì • ì§€í‘œ
    all_metrics.update(calculate_risk_adjusted_metrics(returns, risk_free_rate))
    
    # ë“œë¡œìš°ë‹¤ìš´ ì§€í‘œ
    all_metrics.update(calculate_drawdown_metrics(returns))
    
    # ê¼¬ë¦¬ ìœ„í—˜ ì§€í‘œ
    all_metrics.update(calculate_tail_risk_metrics(returns))
    
    # ì¼ê´€ì„± ì§€í‘œ
    all_metrics.update(calculate_consistency_metrics(returns))
    
    # ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì§€í‘œ
    if benchmark_returns is not None:
        benchmark_metrics = calculate_benchmark_metrics(returns, benchmark_returns)
        all_metrics.update(benchmark_metrics)
    
    logger.success(f"âœ… ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {len(all_metrics)} ì§€í‘œ")
    return all_metrics


def calculate_benchmark_metrics(
    returns: pd.Series,
    benchmark_returns: pd.Series
) -> Dict[str, float]:
    """ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        returns: í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ 
        benchmark_returns: ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ 
        
    Returns:
        ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    # ë°ì´í„° ì •ë ¬
    aligned_data = pd.DataFrame({
        'portfolio': returns,
        'benchmark': benchmark_returns
    }).dropna()
    
    if len(aligned_data) == 0:
        return {}
    
    port_returns = aligned_data['portfolio']
    bench_returns = aligned_data['benchmark']
    
    # ì´ˆê³¼ ìˆ˜ìµë¥ 
    excess_returns = port_returns - bench_returns
    
    # ë² íƒ€
    covariance = np.cov(port_returns, bench_returns)[0, 1]
    benchmark_variance = bench_returns.var()
    
    if benchmark_variance > 0:
        beta = covariance / benchmark_variance
    else:
        beta = 0.0
    
    # ì•ŒíŒŒ (ì—°ìœ¨í™”)
    portfolio_annual = port_returns.mean() * 252
    benchmark_annual = bench_returns.mean() * 252
    alpha = portfolio_annual - (beta * benchmark_annual)
    
    # Tracking Error
    tracking_error = excess_returns.std() * np.sqrt(252)
    
    # Information Ratio
    if tracking_error > 0:
        information_ratio = (excess_returns.mean() * 252) / tracking_error
    else:
        information_ratio = 0.0
    
    # Up/Down Capture Ratios
    up_benchmark = bench_returns[bench_returns > 0]
    down_benchmark = bench_returns[bench_returns < 0]
    
    if len(up_benchmark) > 0:
        up_portfolio = port_returns.loc[up_benchmark.index]
        up_capture = (up_portfolio.mean() / up_benchmark.mean()) if up_benchmark.mean() > 0 else 0.0
    else:
        up_capture = 0.0
    
    if len(down_benchmark) > 0:
        down_portfolio = port_returns.loc[down_benchmark.index]
        down_capture = (down_portfolio.mean() / down_benchmark.mean()) if down_benchmark.mean() < 0 else 0.0
    else:
        down_capture = 0.0
    
    return {
        'alpha': alpha,
        'beta': beta,
        'tracking_error': tracking_error,
        'information_ratio': information_ratio,
        'up_capture': up_capture,
        'down_capture': down_capture,
        'excess_return_annual': excess_returns.mean() * 252
    }


def create_performance_summary(metrics: Dict[str, Any]) -> pd.DataFrame:
    """ì„±ê³¼ ì§€í‘œ ìš”ì•½ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        metrics: ì„±ê³¼ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ìš”ì•½ í…Œì´ë¸” ë°ì´í„°í”„ë ˆì„
    """
    summary_data = []
    
    # ì£¼ìš” ì§€í‘œ ì„ íƒ
    key_metrics = {
        'Total Return': ('total_return', '{:.2%}'),
        'CAGR': ('cagr', '{:.2%}'),
        'Volatility': ('volatility', '{:.2%}'),
        'Sharpe Ratio': ('sharpe_ratio', '{:.3f}'),
        'Sortino Ratio': ('sortino_ratio', '{:.3f}'),
        'Max Drawdown': ('max_drawdown', '{:.2%}'),
        'Calmar Ratio': ('calmar_ratio', '{:.3f}'),
        'VaR (95%)': ('var_95', '{:.2%}'),
        'CVaR (95%)': ('cvar_95', '{:.2%}'),
        'Win Rate': ('win_rate', '{:.2%}'),
        'Profit Factor': ('profit_factor', '{:.3f}'),
        'Best Day': ('best_day', '{:.2%}'),
        'Worst Day': ('worst_day', '{:.2%}')
    }
    
    for label, (key, format_str) in key_metrics.items():
        if key in metrics:
            value = metrics[key]
            if pd.isna(value) or np.isinf(value):
                formatted_value = 'N/A'
            else:
                try:
                    formatted_value = format_str.format(value)
                except (ValueError, TypeError):
                    formatted_value = str(value)
            
            summary_data.append({
                'Metric': label,
                'Value': formatted_value
            })
    
    return pd.DataFrame(summary_data)


def plot_performance_charts(
    returns: pd.Series,
    benchmark_returns: Optional[pd.Series] = None,
    save_path: Optional[str] = None
) -> Dict[str, Any]:
    """ì„±ê³¼ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        returns: í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ 
        benchmark_returns: ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ 
        save_path: ì €ì¥ ê²½ë¡œ
        
    Returns:
        ì°¨íŠ¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        # ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('default')
        sns.set_palette("husl")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Portfolio Performance Analysis', fontsize=16, fontweight='bold')
        
        # 1. ëˆ„ì  ìˆ˜ìµë¥ 
        cumulative = (1 + returns).cumprod()
        axes[0, 0].plot(cumulative.index, cumulative.values, label='Portfolio', linewidth=2)
        
        if benchmark_returns is not None:
            bench_cumulative = (1 + benchmark_returns).cumprod()
            axes[0, 0].plot(bench_cumulative.index, bench_cumulative.values, 
                          label='Benchmark', linewidth=2, alpha=0.7)
        
        axes[0, 0].set_title('Cumulative Returns')
        axes[0, 0].set_ylabel('Cumulative Return')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ë“œë¡œìš°ë‹¤ìš´
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max
        
        axes[0, 1].fill_between(drawdown.index, drawdown.values, 0, 
                               alpha=0.3, color='red', label='Drawdown')
        axes[0, 1].plot(drawdown.index, drawdown.values, color='red', linewidth=1)
        axes[0, 1].set_title('Drawdown')
        axes[0, 1].set_ylabel('Drawdown')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ìˆ˜ìµë¥  íˆìŠ¤í† ê·¸ë¨
        axes[1, 0].hist(returns.values, bins=50, alpha=0.7, edgecolor='black')
        axes[1, 0].axvline(returns.mean(), color='red', linestyle='--', 
                          label=f'Mean: {returns.mean():.4f}')
        axes[1, 0].set_title('Return Distribution')
        axes[1, 0].set_xlabel('Daily Return')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ë¡¤ë§ ìƒ¤í”„ ë¹„ìœ¨
        rolling_sharpe = returns.rolling(window=252).apply(
            lambda x: (x.mean() * 252) / (x.std() * np.sqrt(252))
        )
        
        axes[1, 1].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=2)
        axes[1, 1].axhline(0, color='black', linestyle='-', alpha=0.3)
        axes[1, 1].set_title('Rolling Sharpe Ratio (1-Year)')
        axes[1, 1].set_ylabel('Sharpe Ratio')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ğŸ“Š ì„±ê³¼ ì°¨íŠ¸ ì €ì¥: {save_path}")
        
        return {
            'figure': fig,
            'axes': axes,
            'cumulative_returns': cumulative,
            'drawdown': drawdown,
            'rolling_sharpe': rolling_sharpe
        }
        
    except ImportError:
        logger.warning("matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


# CLI ì§ì ‘ ì‹¤í–‰ìš©
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    
    # ì„ì˜ì˜ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ ìƒì„±
    n_days = 252
    daily_returns = np.random.normal(0.0005, 0.015, n_days)  # í‰ê·  0.05%, í‘œì¤€í¸ì°¨ 1.5%
    
    dates = pd.date_range('2023-01-01', periods=n_days, freq='D')
    returns_series = pd.Series(daily_returns, index=dates)
    
    print("ğŸ§ª ì„±ê³¼ ì§€í‘œ ê³„ì‚° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    metrics = calculate_performance_metrics(returns_series)
    
    # ìš”ì•½ í…Œì´ë¸” ìƒì„±
    summary = create_performance_summary(metrics)
    print("\nğŸ“Š ì„±ê³¼ ì§€í‘œ ìš”ì•½:")
    print(summary.to_string(index=False))
    
    # ì£¼ìš” ì§€í‘œ ì¶œë ¥
    print(f"\nğŸ¯ ì£¼ìš” ì§€í‘œ:")
    print(f"CAGR: {metrics.get('cagr', 0):.2%}")
    print(f"ë³€ë™ì„±: {metrics.get('volatility', 0):.2%}")
    print(f"ìƒ¤í”„ ë¹„ìœ¨: {metrics.get('sharpe_ratio', 0):.3f}")
    print(f"ìµœëŒ€ ë‚™í­: {metrics.get('max_drawdown', 0):.2%}")
    print(f"ì¹¼ë§ˆ ë¹„ìœ¨: {metrics.get('calmar_ratio', 0):.3f}")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")