"""
Yahoo Finance ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ

yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
"""

from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
import warnings

import pandas as pd
import yfinance as yf
from loguru import logger

from ..config import settings
from ..utils.paths import get_raw_data_path, ensure_dir


warnings.filterwarnings("ignore", category=UserWarning, module="yfinance")


def collect_single_ticker(
    ticker: str,
    start_date: str,
    end_date: str,
    interval: str = "1d",
    save: bool = True
) -> Optional[pd.DataFrame]:
    """ë‹¨ì¼ ì¢…ëª© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ (ì˜ˆ: 'AAPL')
        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
        interval: ë°ì´í„° ê°„ê²© ('1d', '1h', '5m' ë“±)
        save: íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        
    Returns:
        ìˆ˜ì§‘ëœ ë°ì´í„°í”„ë ˆì„ ë˜ëŠ” None (ì‹¤íŒ¨ì‹œ)
    """
    try:
        logger.info(f"ğŸ“¥ {ticker} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
        
        # yfinance ê°ì²´ ìƒì„±
        stock = yf.Ticker(ticker)
        
        # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        data = stock.history(
            start=start_date,
            end=end_date,
            interval=interval,
            auto_adjust=True,  # ë°°ë‹¹, ë¶„í•  ì¡°ì •
            prepost=False      # ì‹œê°„ì™¸ ê±°ë˜ ì œì™¸
        )
        
        if data.empty:
            logger.warning(f"âš ï¸ {ticker}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        data.columns = [col.replace(' ', '_').lower() for col in data.columns]
        
        # ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        data = data.reset_index()
        
        # ì¸ë±ìŠ¤ ì»¬ëŸ¼ëª… í™•ì¸ ë° ì²˜ë¦¬
        index_col = data.columns[0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ë‚ ì§œ
        if index_col.lower() in ['date', 'datetime', 'timestamp']:
            data.rename(columns={index_col: 'date'}, inplace=True)
        else:
            data['date'] = data.index
        
        data['date'] = pd.to_datetime(data['date']).dt.date
        
        # ì¢…ëª© ì½”ë“œ ì¶”ê°€
        data['ticker'] = ticker
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        columns_order = ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume']
        data = data[columns_order]
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        data = data.dropna()
        
        if save:
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            save_dir = get_raw_data_path() / start_date
            ensure_dir(save_dir)
            
            file_path = save_dir / f"{ticker}.csv"
            data.to_csv(file_path, index=False)
            logger.info(f"ğŸ’¾ {ticker} ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        
        logger.success(f"âœ… {ticker} ìˆ˜ì§‘ ì™„ë£Œ: {len(data)} í–‰")
        return data
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return None


def collect_multiple_tickers(
    tickers: List[str],
    start_date: str,
    end_date: str,
    interval: str = "1d",
    save: bool = True
) -> Dict[str, pd.DataFrame]:
    """ì—¬ëŸ¬ ì¢…ëª© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        interval: ë°ì´í„° ê°„ê²©
        save: íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        
    Returns:
        ì¢…ëª©ë³„ ë°ì´í„°í”„ë ˆì„ ë”•ì…”ë„ˆë¦¬
    """
    logger.info(f"ğŸ“Š ì—¬ëŸ¬ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {len(tickers)} ì¢…ëª©")
    
    results = {}
    success_count = 0
    
    for ticker in tickers:
        data = collect_single_ticker(ticker, start_date, end_date, interval, save)
        if data is not None:
            results[ticker] = data
            success_count += 1
    
    logger.info(f"ğŸ¯ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(tickers)} ì¢…ëª© ì„±ê³µ")
    return results


def collect_data(
    tickers: List[str],
    start_date: str,
    end_date: str,
    interval: str = "1d"
) -> Dict[str, pd.DataFrame]:
    """ë©”ì¸ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (CLIì—ì„œ í˜¸ì¶œ)
    
    Args:
        tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        interval: ë°ì´í„° ê°„ê²©
        
    Returns:
        ìˆ˜ì§‘ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    return collect_multiple_tickers(tickers, start_date, end_date, interval, save=True)


def get_stock_info(ticker: str) -> Optional[Dict[str, Any]]:
    """ì¢…ëª© ê¸°ë³¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        ì¢…ëª© ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        
        # ì£¼ìš” ì •ë³´ë§Œ ì¶”ì¶œ
        key_info = {
            'symbol': info.get('symbol', ticker),
            'shortName': info.get('shortName', ''),
            'longName': info.get('longName', ''),
            'sector': info.get('sector', ''),
            'industry': info.get('industry', ''),
            'marketCap': info.get('marketCap', 0),
            'currency': info.get('currency', 'USD'),
            'exchange': info.get('exchange', ''),
            'country': info.get('country', ''),
        }
        
        return key_info
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def validate_tickers(tickers: List[str]) -> List[str]:
    """ìœ íš¨í•œ ì¢…ëª© ì½”ë“œë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    
    Args:
        tickers: ê²€ì¦í•  ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìœ íš¨í•œ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    """
    valid_tickers = []
    
    logger.info(f"ğŸ” ì¢…ëª© ì½”ë“œ ê²€ì¦ ì‹œì‘: {len(tickers)} ì¢…ëª©")
    
    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            # ìµœê·¼ 1ì¼ ë°ì´í„°ë¡œ ìœ íš¨ì„± ê²€ì‚¬
            test_data = stock.history(period="1d")
            
            if not test_data.empty:
                valid_tickers.append(ticker)
                logger.debug(f"âœ… {ticker}: ìœ íš¨")
            else:
                logger.warning(f"âš ï¸ {ticker}: ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            logger.warning(f"âš ï¸ {ticker}: ê²€ì¦ ì‹¤íŒ¨ - {e}")
    
    logger.info(f"ğŸ¯ ê²€ì¦ ì™„ë£Œ: {len(valid_tickers)}/{len(tickers)} ì¢…ëª© ìœ íš¨")
    return valid_tickers


def update_existing_data(
    ticker: str,
    last_date: Optional[str] = None
) -> Optional[pd.DataFrame]:
    """ê¸°ì¡´ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        last_date: ë§ˆì§€ë§‰ ë°ì´í„° ë‚ ì§œ (ì—†ìœ¼ë©´ ìë™ ê°ì§€)
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ë°ì´í„°
    """
    try:
        # ê¸°ì¡´ íŒŒì¼ ì°¾ê¸°
        raw_dir = get_raw_data_path()
        existing_files = list(raw_dir.rglob(f"{ticker}.csv"))
        
        if not existing_files:
            logger.warning(f"âš ï¸ {ticker}: ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°
        latest_file = max(existing_files, key=lambda x: x.parent.name)
        existing_data = pd.read_csv(latest_file)
        
        if last_date is None:
            # ë§ˆì§€ë§‰ ë‚ ì§œ ìë™ ê°ì§€
            existing_data['date'] = pd.to_datetime(existing_data['date'])
            last_date = existing_data['date'].max().strftime('%Y-%m-%d')
        
        # ë‹¤ìŒ ë‚ ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ì§‘
        from datetime import datetime, timedelta
        next_date = (pd.to_datetime(last_date) + timedelta(days=1)).strftime('%Y-%m-%d')
        today = datetime.now().strftime('%Y-%m-%d')
        
        if next_date >= today:
            logger.info(f"ğŸ¯ {ticker}: ì´ë¯¸ ìµœì‹  ë°ì´í„°ì…ë‹ˆë‹¤")
            return existing_data
        
        # ìƒˆ ë°ì´í„° ìˆ˜ì§‘
        new_data = collect_single_ticker(ticker, next_date, today, save=False)
        
        if new_data is not None and not new_data.empty:
            # ë°ì´í„° ë³‘í•©
            combined_data = pd.concat([existing_data, new_data], ignore_index=True)
            combined_data = combined_data.drop_duplicates(subset=['date', 'ticker'])
            combined_data = combined_data.sort_values(['date'])
            
            # íŒŒì¼ ë®ì–´ì“°ê¸°
            combined_data.to_csv(latest_file, index=False)
            logger.success(f"âœ… {ticker} ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: +{len(new_data)} í–‰")
            
            return combined_data
        else:
            logger.info(f"ğŸ¯ {ticker}: ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return existing_data
            
    except Exception as e:
        logger.error(f"âŒ {ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return None


# CLI ì§ì ‘ ì‹¤í–‰ìš©
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 4:
        print("ì‚¬ìš©ë²•: python -m src.ingest.yfinance_cli TICKER START_DATE END_DATE")
        sys.exit(1)
    
    ticker = sys.argv[1]
    start = sys.argv[2] 
    end = sys.argv[3]
    
    data = collect_single_ticker(ticker, start, end)
    if data is not None:
        print(f"âœ… {ticker} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(data)} í–‰")
    else:
        print(f"âŒ {ticker} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        sys.exit(1)